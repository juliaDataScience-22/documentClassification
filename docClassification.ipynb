{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnxJpyW3i-_k"
      },
      "source": [
        "# Document Classification\n",
        "### Team The p < 0.05 Team - Haig Bedros, Noori Selina, Julia Ferris, Matthew Roland\n",
        "\n",
        "\n",
        "It can be useful to classify new \"test\" documents using already classified \"training\" documents. A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. Here is one example of such data: UCI Machine Learning Repository: Spambase Data Set.\n",
        "\n",
        "For this project, we used the BBC Full Text Document Classification dataset from Kaggle. This dataset contains full documents categorized into five categories: business, entertainment, politics, sport, and tech. \n",
        "\n",
        "The goal of our text classification is to predict the category of new documents in the test set.\n",
        "\n",
        "Link to the dataset: https://www.kaggle.com/datasets/shivamkushwaha/bbc-full-text-document-classification?resource=download\n",
        "\n",
        "The models we used include the Naive Bayes Classifier, Support Vector Machines, and Random Forests. The results were compared for accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6AbGJ1iUgqc"
      },
      "source": [
        "## 1. Load and Process the Documents\n",
        "\n",
        "The zip file of the dataset is extracted, and the documents from different categories are loaded and processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_z7ckYOUkFGR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents: 2194\n",
            "Sample document: (['Asian', 'quake', 'hits', 'European', 'shares', 'Shares', 'in', \"Europe's\", 'leading', 'reinsurers', 'and', 'travel', 'firms', 'have', 'fallen', 'as', 'the', 'scale', 'of', 'the', 'damage', 'wrought', 'by', 'tsunamis', 'across', 'south', 'Asia', 'has', 'become', 'apparent.', 'More', 'than', '23,000', 'people', 'have', 'been', 'killed', 'following', 'a', 'massive', 'underwater', 'earthquake', 'and', 'many', 'of', 'the', 'worst', 'hit', 'areas', 'are', 'popular', 'tourist', 'destinations.', 'Reisurance', 'firms', 'such', 'as', 'Swiss', 'Re', 'and', 'Munich', 'Re', 'lost', 'value', 'as', 'investors', 'worried', 'about', 'rebuilding', 'costs.', 'But', 'the', 'disaster', 'has', 'little', 'impact', 'on', 'stock', 'markets', 'in', 'the', 'US', 'and', 'Asia.', 'Currencies', 'including', 'the', 'Thai', 'baht', 'and', 'Indonesian', 'rupiah', 'weakened', 'as', 'analysts', 'warned', 'that', 'economic', 'growth', 'may', 'slow.', '\"It', 'came', 'at', 'the', 'worst', 'possible', 'time,\"', 'said', 'Hans', 'Goetti,', 'a', 'Singapore-based', 'fund', 'manager.', '\"The', 'impact', 'on', 'the', 'tourist', 'industry', 'is', 'pretty', 'devastating,', 'especially', 'in', 'Thailand.\"', 'Travel-related', 'shares', 'dropped', 'in', 'Europe,', 'with', 'companies', 'such', 'as', \"Germany's\", 'TUI', 'and', 'Lufthansa', 'and', \"France's\", 'Club', 'Mediterranne', 'sliding.', 'Insurers', 'and', 'reinsurance', 'firms', 'were', 'also', 'under', 'pressure', 'in', 'Europe.', 'Shares', 'in', 'Munich', 'Re', 'and', 'Swiss', 'Re', '-', 'the', \"world's\", 'two', 'biggest', 'reinsurers', '-', 'both', 'fell', '1.7%', 'as', 'the', 'market', 'speculated', 'about', 'the', 'cost', 'of', 'rebuilding', 'in', 'Asia.', 'Zurich', 'Financial,', 'Allianz', 'and', 'Axa', 'also', 'suffered', 'a', 'decline', 'in', 'value.', 'However,', 'their', 'losses', 'were', 'much', 'smaller,', 'reflecting', 'the', \"market's\", 'view', 'that', 'reinsurers', 'were', 'likely', 'to', 'pick', 'up', 'the', 'bulk', 'of', 'the', 'costs.', 'Worries', 'about', 'the', 'size', 'of', 'insurance', 'liabilities', 'dragged', 'European', 'shares', 'down,', 'although', 'the', 'impact', 'was', 'exacerbated', 'by', 'light', 'post-Christmas', 'trading.', \"Germany's\", 'benchmark', 'Dax', 'index', 'closed', 'the', 'day', '16.29', 'points', 'lower', 'at', '3.817.69', 'while', \"France's\", 'Cac', 'index', 'of', 'leading', 'shares', 'fell', '5.07', 'points', 'to', '3.817.69.', 'Investors', 'pointed', 'out,', 'however,', 'that', 'declines', 'probably', 'would', 'be', 'industry', 'specific,', 'with', 'the', 'travel', 'and', 'insurance', 'firms', 'hit', 'hardest.', '\"It\\'s', 'still', 'too', 'early', 'for', 'concrete', 'damage', 'figures,\"', 'Swiss', \"Re's\", 'spokesman', 'Floiran', 'Woest', 'told', 'Associated', 'Press.', '\"That', 'also', 'has', 'to', 'do', 'with', 'the', 'fact', 'that', 'the', 'damage', 'is', 'very', 'widely', 'spread', 'geographically.\"', 'The', 'unfolding', 'scale', 'of', 'the', 'disaster', 'in', 'south', 'Asia', 'had', 'little', 'immediate', 'impact', 'on', 'US', 'shares,', 'however.', 'The', 'Dow', 'Jones', 'index', 'had', 'risen', '20.54', 'points,', 'or', '0.2%,', 'to', '10,847.66', 'by', 'late', 'morning', 'as', 'analsyts', 'were', 'cheered', 'by', 'more', 'encouraging', 'reports', 'from', 'retailers', 'about', 'post-Christmas', 'sales.', 'In', 'Asian', 'markets,', 'adjustments', 'were', 'made', 'quickly', 'to', 'account', 'for', 'lower', 'earnings', 'and', 'the', 'cost', 'of', 'repairs.', 'Thai', 'Airways', 'shed', 'almost', '4%.', 'The', 'country', 'relies', 'on', 'tourism', 'for', 'about', '6%', 'of', 'its', 'total', 'economy.', 'Singapore', 'Airlines', 'dropped', '2.6%.', 'About', '5%', 'of', \"Singapore's\", 'annual', 'gross', 'domestic', 'product', '(GDP)', 'comes', 'from', 'tourism.', \"Malaysia's\", 'budget', 'airline,', 'AirAsia', 'fell', '2.9%.', 'Resort', 'operator', 'Tanco', 'Holdings', 'slumped', '5%.', 'Travel', 'companies', 'also', 'took', 'a', 'hit,', 'with', \"Japan's\", 'Kinki', 'Nippon', 'sliding', '1.5%', 'and', 'HIS', 'dropping', '3.3%.', 'However,', 'the', 'overall', 'impact', 'on', \"Asia's\", 'largest', 'stock', 'market,', \"Japan's\", 'Nikkei,', 'was', 'slight.', 'Shares', 'fell', 'just', '0.03%.', 'Concerns', 'about', 'the', 'strength', 'of', 'economic', 'growth', 'going', 'forward', 'weighed', 'on', 'the', 'currency', 'markets.', 'The', 'Indonesian', 'rupiah', 'lost', 'as', 'much', 'as', '0.6%', 'against', 'the', 'US', 'dollar,', 'before', 'bouncing', 'back', 'slightly', 'to', 'trade', 'at', '9,300.', 'The', 'Thai', 'baht', 'lost', '0.3%', 'against', 'the', 'US', 'currency,', 'trading', 'at', '39.10.', 'In', 'India,', 'where', 'more', 'than', '2,000', 'people', 'are', 'thought', 'to', 'have', 'died,', 'the', 'rupee', 'shed', '0.1%', 'against', 'the', 'dollar', 'Analysts', 'said', 'that', 'it', 'was', 'difficult', 'to', 'predict', 'the', 'total', 'cost', 'of', 'the', 'disaster', 'and', 'warned', 'that', 'share', 'prices', 'and', 'currencies', 'would', 'come', 'under', 'increasing', 'pressure', 'as', 'the', 'bills', 'mounted.'], 'business')\n",
            "Total words: 844994\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Function to get all .txt files from a local directory\n",
        "def get_txt_files_from_local_directory(category_path):\n",
        "    files = []\n",
        "    for filename in os.listdir(category_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            files.append(filename)\n",
        "    return files\n",
        "\n",
        "base_path = \"/Users/haigbedros/Desktop/MSDS/Summer 24/620/HW/documentClassification/data/bbc\"\n",
        "category_paths = {\n",
        "    'business': os.path.join(base_path, 'business'),\n",
        "    'entertainment': os.path.join(base_path, 'entertainment'),\n",
        "    'politics': os.path.join(base_path, 'politics'),\n",
        "    'sport': os.path.join(base_path, 'sport'),\n",
        "    'tech': os.path.join(base_path, 'tech')\n",
        "}\n",
        "\n",
        "documents = []\n",
        "all_words_list = []\n",
        "\n",
        "for category, category_path in category_paths.items():\n",
        "    txt_files = get_txt_files_from_local_directory(category_path)\n",
        "    \n",
        "    for filename in txt_files:\n",
        "        file_path = os.path.join(category_path, filename)\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                words = file.read().split()\n",
        "        except UnicodeDecodeError:\n",
        "            with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
        "                words = file.read().split()\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to read {file_path}: {e}\")\n",
        "            continue\n",
        "        documents.append((words, category))\n",
        "        all_words_list.extend(w.lower() for w in words)\n",
        "\n",
        "# Data verification\n",
        "print(f\"Total documents: {len(documents)}\")\n",
        "print(f\"Sample document: {documents[0]}\")\n",
        "print(f\"Total words: {len(all_words_list)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKuIOQnDQaiq"
      },
      "source": [
        "## 2. Feature Extraction\n",
        "Extract features using NLTK for the Naive Bayes classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "luNxc3mXHpY4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 1535\n",
            "Test set size: 659\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "import random\n",
        "\n",
        "all_words = FreqDist(w.lower() for w in all_words_list)\n",
        "word_features = list(all_words)[:1000]\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features\n",
        "\n",
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "\n",
        "random.shuffle(featuresets)\n",
        "total_samples = len(featuresets)\n",
        "train_size = int(0.7 * total_samples)\n",
        "train_set, test_set = featuresets[:train_size], featuresets[train_size:]\n",
        "\n",
        "# data verification\n",
        "print(f\"Train set size: {len(train_set)}\")\n",
        "print(f\"Test set size: {len(test_set)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-lHoMoORPF0"
      },
      "source": [
        "## 3. Training and Evaluation of Naive Bayes Classifier\n",
        "Train and evaluate the NLTK Naive Bayes classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvkUS6tsIigY",
        "outputId": "3f83c4f2-1865-49b6-d9ff-30d167a3a513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Naive Bayes Accuracy: 0.9195751138088012\n",
            "Most Informative Features\n",
            "          contains(film) = True           entert : sport  =     96.2 : 1.0\n",
            "    contains(technology) = True             tech : sport  =     96.1 : 1.0\n",
            "        contains(market) = True           busine : sport  =     80.7 : 1.0\n",
            "       contains(million) = True             tech : sport  =     74.4 : 1.0\n",
            "    contains(government) = True           politi : sport  =     74.0 : 1.0\n",
            "       contains(digital) = True             tech : busine =     67.7 : 1.0\n",
            "      contains(minister) = True           politi : entert =     62.0 : 1.0\n",
            "          contains(star) = True           entert : politi =     56.0 : 1.0\n",
            "         contains(phone) = True             tech : sport  =     55.9 : 1.0\n",
            "          contains(firm) = True             tech : entert =     54.2 : 1.0\n"
          ]
        }
      ],
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print('NLTK Naive Bayes Accuracy:', nltk.classify.accuracy(classifier, test_set))\n",
        "classifier.show_most_informative_features(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MlsChmQVtuj"
      },
      "source": [
        "**Naive Bayes Classifier Results:**\n",
        "- **Accuracy**: 92%\n",
        "- **Summary**: The NLTK Naive Bayes classifier achieved an accuracy of 92%, meaning it correctly classified the documents into their respective categories (business, entertainment, politics, sport, and tech) 92% of the time. The most informative features were words like 'film', 'technology', 'market', 'million', and 'government', which had the highest impact on the classification decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-obqjqjBRVIN"
      },
      "source": [
        "## 4. Prepare Data for SVM Classifier using TF-IDF\n",
        "Convert the documents to TF-IDF features for use with the SVM classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "acSJv0EiIm2r"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def document_to_string(document):\n",
        "    return ' '.join(document)\n",
        "\n",
        "documents_str = [document_to_string(doc) for doc, _ in documents]\n",
        "labels = [label for _, label in documents]\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "X = vectorizer.fit_transform(documents_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JL4AFisJiw6"
      },
      "source": [
        "\n",
        "Split the data into training (70%) and testing (30%) sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "64cGpKkEJkc9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVq_ZBbORsY4"
      },
      "source": [
        "## 5. Train and Evaluate the SVM Classifier\n",
        "Train and evaluate the SVM classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDtdUQCrRu-h",
        "outputId": "e6695bc7-d770-4b8e-8f92-ec122b5f53b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.9696509863429439\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.94      0.96      0.95       150\n",
            "entertainment       0.97      0.95      0.96       119\n",
            "     politics       0.95      0.97      0.96       118\n",
            "        sport       0.99      0.99      0.99       149\n",
            "         tech       0.99      0.97      0.98       123\n",
            "\n",
            "     accuracy                           0.97       659\n",
            "    macro avg       0.97      0.97      0.97       659\n",
            " weighted avg       0.97      0.97      0.97       659\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "svm_classifier = LinearSVC()\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "svm_predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(f'SVM Accuracy: {svm_accuracy}')\n",
        "print(classification_report(y_test, svm_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3jNKaGwWsrU"
      },
      "source": [
        "**SVM Classifier Results:**\n",
        "- **Accuracy**: 97%\n",
        "- **Summary**: The SVM classifier achieved an accuracy of 97%, meaning it correctly classified the documents almost all of the time. Each category (business, entertainment, politics, sport, and tech) was classified with very high accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UVcl80_R3-I"
      },
      "source": [
        "## 6. Train and Evaluate the Random Forest Classifier\n",
        "Train and Evaluate the Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3wYSBcwR2cx",
        "outputId": "c909b7e9-691d-422b-9caa-52c5e19fd37e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.9590288315629742\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.91      0.97      0.94       150\n",
            "entertainment       0.97      0.93      0.95       119\n",
            "     politics       0.97      0.95      0.96       118\n",
            "        sport       1.00      0.99      0.99       149\n",
            "         tech       0.96      0.94      0.95       123\n",
            "\n",
            "     accuracy                           0.96       659\n",
            "    macro avg       0.96      0.96      0.96       659\n",
            " weighted avg       0.96      0.96      0.96       659\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
        "print(classification_report(y_test, rf_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvb5w6a2XNNO"
      },
      "source": [
        "**Random Forest Classifier Results:**\n",
        "- **Accuracy**: 96%\n",
        "- **Summary**: The Random Forest classifier achieved an accuracy of 96%, meaning it correctly classified the documents most of the time. Each category (business, entertainment, politics, sport, and tech) was classified with high precision and recall, indicating the classifier's strong performance across all categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHJwGGgqXPg9"
      },
      "source": [
        "## 7. Conclusion\n",
        "- **Naive Bayes Classifier**:\n",
        "  - **Accuracy**: 92%\n",
        "  - **Summary**: The Naive Bayes classifier correctly classified most documents and identified key words for each category.\n",
        "\n",
        "- **SVM Classifier**:\n",
        "  - **Accuracy**: 97%\n",
        "  - **Summary**: The SVM classifier was the most accurate, effectively classifying documents with very high precision and recall.\n",
        "\n",
        "- **Random Forest Classifier**:\n",
        "  - **Accuracy**: 96%\n",
        "  - **Summary**: The Random Forest classifier also performed well, correctly classifying a large majority of documents.\n",
        "\n",
        "- **Key Outcome**:\n",
        "  - The SVM classifier was the best model for classifying documents into business, entertainment, politics, sport, and tech categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNZcU6mUi-_t"
      },
      "source": [
        "Citation:\n",
        "\n",
        "D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

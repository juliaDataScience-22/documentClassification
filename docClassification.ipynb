{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code here is just from the textbook so far. More will be added soon.\n",
    "\n",
    "The data is downloaded first, and then the rest of the code is from the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from nltk import FreqDist\n",
    "\n",
    "data_path = 'C:/Users/TEMP.JULIA_PC/Desktop/bbc'\n",
    "\n",
    "documents = []\n",
    "\n",
    "all_words_list = []\n",
    "\n",
    "for category in ['business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "    category_path = os.path.join(data_path, category)\n",
    "    for filename in os.listdir(category_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(category_path, filename)\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                    words = file.read().split()\n",
    "            except UnicodeDecodeError:\n",
    "                with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "                    words = file.read().split()\n",
    "            documents.append((words, category))\n",
    "            \n",
    "            all_words_list.extend(w.lower() for w in words)\n",
    "\n",
    "all_words = FreqDist(all_words_list)\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code from textbook but modified for the data. The accuracy is 0.894, which is actually very good considering it is not the final draft of this, and we haven't even tried Random Forests yet.\n",
    "\n",
    "Might want to change below code (like where the split for test and train is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8940269749518305\n",
      "Most Informative Features\n",
      "          contains(game) = True            sport : busine =     39.7 : 1.0\n",
      "    contains(technology) = True             tech : politi =     38.6 : 1.0\n",
      "         contains(plans) = True           politi : sport  =     38.2 : 1.0\n",
      "    contains(government) = True           politi : sport  =     37.4 : 1.0\n",
      "        contains(leader) = True           politi : entert =     34.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "all_words = nltk.FreqDist(w.lower() for w in all_words)\n",
    "word_features = list(all_words)[:1000]\n",
    "\n",
    "\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "\n",
    "total_samples = len(featuresets)\n",
    "ind1 = int(0.7 * total_samples)\n",
    "\n",
    "train_set, test_set = featuresets[ind1:], featuresets[:ind1]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation:\n",
    "\n",
    "D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

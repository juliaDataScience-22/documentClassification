{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnxJpyW3i-_k"
      },
      "source": [
        "# Document Classification\n",
        "### Team The p < 0.05 Team - Haig Bedros, Noori Selina, Julia Ferris, Matthew Roland\n",
        "\n",
        "\n",
        "It can be useful to classify new \"test\" documents using already classified \"training\" documents. A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. Here is one example of such data: UCI Machine Learning Repository: Spambase Data Set.\n",
        "\n",
        "For this project, we used the BBC Full Text Document Classification dataset from Kaggle. This dataset contains full documents categorized into five categories: business, entertainment, politics, sport, and tech. The goal of our text classification is to predict the category of new documents in the test set.\n",
        "\n",
        "The models we used include the Naive Bayes Classifier, Support Vector Machines, and Random Forests. The results were compared for accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/bbc'"
      ],
      "metadata": {
        "id": "NU2SDyuXmbHZ",
        "outputId": "3a37be44-b79e-45e0-d8fa-a1df33711914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load and Process the Documents\n",
        "\n",
        "The zip file of the dataset is extracted, and the documents from different categories are loaded and processed."
      ],
      "metadata": {
        "id": "C6AbGJ1iUgqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "documents = []\n",
        "all_words_list = []\n",
        "\n",
        "for category in ['business', 'entertainment', 'politics', 'sport', 'tech']:\n",
        "    category_path = os.path.join(data_path, category)\n",
        "    for filename in os.listdir(category_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            filepath = os.path.join(category_path, filename)\n",
        "            try:\n",
        "                with open(filepath, 'r', encoding='utf-8') as file:\n",
        "                    words = file.read().split()\n",
        "            except UnicodeDecodeError:\n",
        "                with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
        "                    words = file.read().split()\n",
        "            documents.append((words, category))\n",
        "            all_words_list.extend(w.lower() for w in words)"
      ],
      "metadata": {
        "id": "_z7ckYOUkFGR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature Extraction\n",
        "Extract features using NLTK for the Naive Bayes classifier."
      ],
      "metadata": {
        "id": "dKuIOQnDQaiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "\n",
        "all_words = FreqDist(w.lower() for w in all_words_list)\n",
        "word_features = list(all_words)[:1000]\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features\n",
        "\n",
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "\n",
        "random.shuffle(featuresets)\n",
        "total_samples = len(featuresets)\n",
        "train_size = int(0.7 * total_samples)\n",
        "train_set, test_set = featuresets[:train_size], featuresets[train_size:]"
      ],
      "metadata": {
        "id": "luNxc3mXHpY4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training and Evaluation of Naive Bayes Classifier\n",
        "Train and evaluate the NLTK Naive Bayes classifier."
      ],
      "metadata": {
        "id": "j-lHoMoORPF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print('NLTK Naive Bayes Accuracy:', nltk.classify.accuracy(classifier, test_set))\n",
        "classifier.show_most_informative_features(10)"
      ],
      "metadata": {
        "id": "JvkUS6tsIigY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f83c4f2-1865-49b6-d9ff-30d167a3a513"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Naive Bayes Accuracy: 0.8907185628742516\n",
            "Most Informative Features\n",
            "        contains(market) = True           busine : sport  =     85.8 : 1.0\n",
            "    contains(government) = True           politi : sport  =     79.6 : 1.0\n",
            "    contains(technology) = True             tech : entert =     78.4 : 1.0\n",
            "       contains(digital) = True             tech : busine =     76.4 : 1.0\n",
            "       contains(million) = True             tech : sport  =     68.1 : 1.0\n",
            "         contains(music) = True           entert : busine =     66.4 : 1.0\n",
            "          contains(star) = True           entert : politi =     54.4 : 1.0\n",
            "         contains(actor) = True           entert : busine =     51.5 : 1.0\n",
            "        contains(shares) = True           busine : sport  =     50.7 : 1.0\n",
            "      contains(industry) = True             tech : sport  =     49.1 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Classifier Results:**\n",
        "- **Accuracy**: 89.1%\n",
        "- **Summary**: The NLTK Naive Bayes classifier achieved an accuracy of 89.1%, meaning it correctly classified the documents into their respective categories (business, entertainment, politics, sport, and tech) 89.1% of the time. The most informative features were words like 'market', 'government', 'technology', 'digital', and 'million', which had the highest impact on the classification decisions."
      ],
      "metadata": {
        "id": "2MlsChmQVtuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Prepare Data for SVM Classifier using TF-IDF\n",
        "Convert the documents to TF-IDF features for use with the SVM classifier."
      ],
      "metadata": {
        "id": "-obqjqjBRVIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def document_to_string(document):\n",
        "    return ' '.join(document)\n",
        "\n",
        "documents_str = [document_to_string(doc) for doc, _ in documents]\n",
        "labels = [label for _, label in documents]\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "X = vectorizer.fit_transform(documents_str)"
      ],
      "metadata": {
        "id": "acSJv0EiIm2r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Split the data into training (70%) and testing (30%) sets."
      ],
      "metadata": {
        "id": "9JL4AFisJiw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "64cGpKkEJkc9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train and Evaluate the SVM Classifier\n",
        "Train and evaluate the SVM classifier."
      ],
      "metadata": {
        "id": "fVq_ZBbORsY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "svm_classifier = LinearSVC()\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "svm_predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(f'SVM Accuracy: {svm_accuracy}')\n",
        "print(classification_report(y_test, svm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDtdUQCrRu-h",
        "outputId": "e6695bc7-d770-4b8e-8f92-ec122b5f53b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9700598802395209\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.96      0.95      0.95       165\n",
            "entertainment       1.00      0.98      0.99       118\n",
            "     politics       0.95      0.96      0.95       120\n",
            "        sport       0.98      1.00      0.99       140\n",
            "         tech       0.96      0.97      0.96       125\n",
            "\n",
            "     accuracy                           0.97       668\n",
            "    macro avg       0.97      0.97      0.97       668\n",
            " weighted avg       0.97      0.97      0.97       668\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM Classifier Results:**\n",
        "- **Accuracy**: 97.0%\n",
        "- **Summary**: The SVM classifier achieved an accuracy of 97.0%, meaning it correctly classified the documents almost all of the time. Each category (business, entertainment, politics, sport, and tech) was classified with very high accuracy.\n"
      ],
      "metadata": {
        "id": "S3jNKaGwWsrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Train and Evaluate the Random Forest Classifier\n",
        "Train and Evaluate the Random Forest Classifier"
      ],
      "metadata": {
        "id": "3UVcl80_R3-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3wYSBcwR2cx",
        "outputId": "c909b7e9-691d-422b-9caa-52c5e19fd37e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9476047904191617\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.89      0.96      0.92       165\n",
            "entertainment       0.99      0.94      0.97       118\n",
            "     politics       0.93      0.92      0.92       120\n",
            "        sport       0.97      0.99      0.98       140\n",
            "         tech       0.98      0.92      0.95       125\n",
            "\n",
            "     accuracy                           0.95       668\n",
            "    macro avg       0.95      0.95      0.95       668\n",
            " weighted avg       0.95      0.95      0.95       668\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier Results:**\n",
        "- **Accuracy**: 94.8%\n",
        "- **Summary**: The Random Forest classifier achieved an accuracy of 94.8%, meaning it correctly classified the documents most of the time. Each category (business, entertainment, politics, sport, and tech) was classified with high precision and recall, indicating the classifier's strong performance across all categories."
      ],
      "metadata": {
        "id": "hvb5w6a2XNNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusion\n",
        "- **Naive Bayes Classifier**:\n",
        "  - **Accuracy**: 89.1%\n",
        "  - **Summary**: The Naive Bayes classifier correctly classified most documents and identified key words for each category.\n",
        "\n",
        "- **SVM Classifier**:\n",
        "  - **Accuracy**: 97.0%\n",
        "  - **Summary**: The SVM classifier was the most accurate, effectively classifying documents with very high precision and recall.\n",
        "\n",
        "- **Random Forest Classifier**:\n",
        "  - **Accuracy**: 94.8%\n",
        "  - **Summary**: The Random Forest classifier also performed well, correctly classifying a large majority of documents.\n",
        "\n",
        "- **Key Outcome**:\n",
        "  - The SVM classifier was the best model for classifying documents into business, entertainment, politics, sport, and tech categories.\n"
      ],
      "metadata": {
        "id": "oHJwGGgqXPg9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNZcU6mUi-_t"
      },
      "source": [
        "Citation:\n",
        "\n",
        "D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}